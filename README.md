This project is to explore the environment and terrain by mounting a soft senorized finger / leg on a Ur5. This project is in collaboration with University of Cambridge BIRL. This code contains the Python and Arduino code. The description below is for the leg primarily. 
The robot leg was attached to the UR5, and at its base there were 16 barometric sensors embedded using a soft skin. Out of 16 sensors, 4 were not working and are to be disregarded: Sensors 4,8,12, 16. The leg ran over each of the 4 terrains: Al (Aluminium), SP (Sandpaper), Coir and Pebble. To ensure we have sufficient data-points, we ran 3 cycles (1,2,3) and captured the time-series data (pressure)  for all the 16 sensors over the 3 cycles. In addition, for each cycle the leg was pressed on to the terrain for 5 different durations: 1,2,4,6,8 seconds. the objective was to see if there is a difference in consistency and reliability with different durations. 
The data is organized as follows: All the data is stored in the 'Legduty' folder categorised by different terrains: Al (Aluminium), SP (Sandpaper), Coir and Pebble. Each folder contains a text file of the signal captured using the coolterm utility when the robot moves over each terrain. In addition, it also contains a csv file of all the statistical features by sensor and by the number of cycles. 
Example of one surface - Pebble: file 'Pebble_c1_d1' is the data for pebble surface, cycle 1 and duration of 1 second. Therefore there are 15 files - 3 cycles x 5 durations. Each file contains 16 columns, one column for each sensor. and each row is the data, the number of rows depends on the duration.
The above data was processed to capture statistical features : mean, median, SD, range, skewness, etc. of the data and this is in the folder 'Pebble_features_summary. This contains the features and the cycle and duration are labelled in the last two columns.
So far, I have processed the data, compared to see differences between the cycles and if any of the durations provide more consistency. I concluded that there is not much variation between cycles, and that durations of 4 and 6 seconds provide the most consistency. 
So I used that the 4 second data to compare the features by terrain. I simply took 3 features, because they are usually sufficient. The code used for that is 'compare_features.py'. The plots are in Legduty/compare folder.
However, I found that due to the features having differnt ranges, it is best to normalize the data using Scaling. So I repeated Step 7 using normalized data using the code 'compare_features_colorplot.py'. I used 3 different features this time though. The folder Leg_duty\compare\normalized data contains the plots generated which shows the difference. Please note I did not store the data files, simply the plots. But the code can simply be modified to store the data. Also, in the code you need to input the sensor number manually and run the code 12 times. as mentioned avoid sensors 4,8,12,16. 
Next steps: my aim was to create a suitable machine learnable file from this normalized data and apply the XGB Boost to learn and then used a held out test set to classify and predict. I have not been able to do that.
What is not required to be done in my view: Go over the durations and cycles to analyze. as a starting point use the compare_features_colorplot.py to add few lines of code to capture the data file of features per sensor. this will provide a unique classification by sensor of the terrain. for a paper, one can show that with this data alone there is sufficient uniqueness by terrain. 
